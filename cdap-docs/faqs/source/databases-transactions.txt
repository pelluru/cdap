.. meta::
    :author: Cask Data, Inc.
    :copyright: Copyright © 2015 Cask Data, Inc.

:titles-only-global-toc: true

.. _faq-databases-transactions:

====================================
CDAP FAQ: Databases and Transactions
====================================

.. contents::
   :depth: 2
   :local:
   :backlinks: entry
   :class: faq

Databases
=========

Understand the BufferingTable Undo API 
--------------------------------------
I don't understand the expected behavior of the undo API from BufferingTable.
If the input map contains a null value for a column, does this mean we should 
be deleting that entry for the associated column from the persistent store?

::

  /**
   * Undos previously persisted changes. After this method returns we assume that 
   * data can be visible to other table clients (of course other clients may choose 
   * still not to see it based on transaction isolation logic).
   *
   * @param persisted previously persisted changes. Map is described as row->(column->value).
   *                  Map can contain null values which means that the corresponded column was deleted
   * @throws Exception
   */
  protected abstract void undo(NavigableMap<byte[], NavigableMap<byte[], Update>> persisted)
    throws Exception;


Let's say you have these key-value pairs in your BufferingTable::

  a: 1
  b: 2

Then you deleted ``a`` |---| you would then have::

  b: 2

If you called ``undo()`` with ``{a: null}``, then the expected behavior would be to
"undelete" the ``"a"`` key-value pair which was previously deleted, resulting in the original
state::

  a: 1
  b: 2


Are there performance issues with Partition Metadata in CDAP?
-------------------------------------------------------------
Hive has a JIRA ticket to switch from using MySQL as the metadata store to HBase due to
performance issues with a large number (on the order of tens of thousands) of partitions.
Will we run into a similar issue with the partition metadata in CDAP? Does CDAP use the
Hive metastore to back the partition metadata?

CDAP already uses HBase to store the partition metadata. However, if you enable explore
for the dataset, CDAP also creates a Hive table and registers all partitions in Hive. You
may then encounter the same issue when exploring the Hive table. This should not affect
the performance of the dataset in a CDAP application, because the app will not use Hive to
access the data.


Will adding an extra JAR to the classpath enable direct access to CDAP data?
----------------------------------------------------------------------------
We are remembering that we need to include an extra JAR in our classpath when using Hive
to access CDAP data. Is that correct? If so, does that JAR add the bridge to CDAP’s
metadata?

If your dataset is a PartitionedFileSet, you can access it from Hive without additional
jars in the classpath. For other datasets |---| for example, tables |---| you will need to
go through CDAP’s Explore service to submit your SQL.


Transactions
============

What does the "transaction...is not in progress" message mean?
--------------------------------------------------------------
If you are seeing transaction related errors::

  [warn 2015/08/10 22:50:53.299 IST <DatasetTypeManager STARTING> tid=0x24] Transaction 1231000000 is not in progress.
  co.cask.tephra.TransactionNotInProgressException: canCommit() is called for transaction 1231000000 
  that is not in progress (it is known to be invalid)
    at co.cask.tephra.TransactionManager.commit(TransactionManager.java:842)
    at co.cask.tephra.inmemory.InMemoryTxSystemClient.commit(InMemoryTxSystemClient.java:73)
    at co.cask.tephra.TransactionContext.commit(TransactionContext.java:265)
    ...
	
The message ``(it is known to be invalid)`` indicates that the transaction has timed out.
Transactions normally time out after 30 seconds and then are moved to the "invalid" set.
You can either start a long-running transaction [link] or increase the transaction timeout property [link].


Is the @RoundRobin annotation appropriate for stream events? 
-------------------------------------------------------------
Though the documentation only talks about partitioning when consuming from queues, not
streams, the same partitioning strategies |---| FIFO, round-robin, and hash-based |---|
also apply when used with stream events.

The ``@RoundRobin`` annotation is a property of the **flowlet** and it is applicable
irrespective of who (either a stream or another flowlet) is emitting the data to the
flowlet. When a stream is connected to a flowlet, the stream acts as a source which is
basically a file-backed queue. Based on the partitioning strategy specified for the
flowlet, an appropriate instance of the flowlet consumes the event from the queue.


Additional Resources
====================

Ask the CDAP Community for assistance
-------------------------------------

.. include:: cdap-user-googlegroups.txt
